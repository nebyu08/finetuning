{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b8dafa1-2ce4-4ebc-bcfe-aa873acefdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nebiyu/miniconda3/envs/tune/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from datasets import get_dataset_config_names\n",
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed314dce-e4fe-4d37-abb9-8f4f9b7b7e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['books', 'electronics', 'grocery', 'movies', 'restaurants', 'tripadvisor']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains=get_dataset_config_names(\"subjqa\")\n",
    "domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c946cb-29d1-4d7b-8d68-47d5e41e3cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjqa=load_dataset(\"subjqa\",name=\"electronics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65575174-ce61-4fa5-b437-89ae5f24c935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['domain', 'nn_mod', 'nn_asp', 'query_mod', 'query_asp', 'q_reviews_id', 'question_subj_level', 'ques_subj_score', 'is_ques_subjective', 'review_id', 'id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 1295\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['domain', 'nn_mod', 'nn_asp', 'query_mod', 'query_asp', 'q_reviews_id', 'question_subj_level', 'ques_subj_score', 'is_ques_subjective', 'review_id', 'id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 358\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['domain', 'nn_mod', 'nn_asp', 'query_mod', 'query_asp', 'q_reviews_id', 'question_subj_level', 'ques_subj_score', 'is_ques_subjective', 'review_id', 'id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 255\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjqa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e581e9e-176d-4a64-baf7-7f2ef78e3912",
   "metadata": {},
   "source": [
    "# turn the data into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9450b416-67e7-4b99-8a4f-de367744229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs={label:data.to_pandas() for label,data in subjqa.flatten().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f289de08-2602-454a-a0e1-47a3449b706f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train has 1295 number of elements\n",
      "test has 358 number of elements\n",
      "validation has 255 number of elements\n"
     ]
    }
   ],
   "source": [
    "for split,df in dfs.items():\n",
    "    print(f\"{split} has {len(df)} number of elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d994c2e8-df43-41d3-97dd-414bcde16d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_columns=[\"title\",\"question\",\"answers.text\",\"answers.answer_start\",\"context\"]\n",
    "\n",
    "sample=dfs[\"train\"][qa_columns].sample(2,random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaa56a7-a73d-4c42-ab81-4fd12b75f663",
   "metadata": {},
   "source": [
    "# lets load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bacac7e0-9dd9-4df2-9f0a-4fda69ffc14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0f4f3dd-e8d8-4fd4-b433-3534c49a5b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nebiyu/miniconda3/envs/tune/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name=\"deepset/minilm-uncased-squad2\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f05052-7d23-422a-8a75-cc35a459e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How much music can this hold?\"\n",
    "context = \"\"\"An MP3 is about 1 MB/minute, so about 6000 hours depending on \\\n",
    "file size.\"\"\"\n",
    "\n",
    "inputs=tokenizer(question,context,return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8ad6b09-8463-4e7e-b87d-b5723217b51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"8484cf283848\",\n",
      "  \"cluster_name\" : \"docker-cluster\",\n",
      "  \"cluster_uuid\" : \"4G6Yu1Q5R86hprBmt3km6w\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"8.15.1\",\n",
      "    \"build_flavor\" : \"default\",\n",
      "    \"build_type\" : \"docker\",\n",
      "    \"build_hash\" : \"253e8544a65ad44581194068936f2a5d57c2c051\",\n",
      "    \"build_date\" : \"2024-09-02T22:04:47.310170297Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"9.11.1\",\n",
      "    \"minimum_wire_compatibility_version\" : \"7.17.0\",\n",
      "    \"minimum_index_compatibility_version\" : \"7.0.0\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!curl -X GET \"http://localhost:9200\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ba6012-7a29-40ce-bd2e-e45b44993d07",
   "metadata": {},
   "source": [
    "# pass the data into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4424c88-174c-4026-be50-09743a4b1963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaed0789-cff8-46e0-a1df-aab48b958e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/minilm-uncased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model=AutoModelForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62121d8b-d4f5-4746-b5b0-ced54a70649b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-0.9862, -4.7750, -5.4025, -5.2378, -5.2863, -5.5117, -4.9819, -6.1880,\n",
      "         -0.9862,  0.2596, -0.2144, -1.7136,  3.7806,  4.8561, -1.0546, -3.9097,\n",
      "         -1.7374, -4.5944, -1.4278,  3.9949,  5.0391, -0.2018, -3.0193, -4.8549,\n",
      "         -2.3107, -3.5110, -3.5713, -0.9862]]), end_logits=tensor([[-0.9623, -5.4733, -5.0326, -5.1639, -5.4278, -5.5151, -5.1749, -4.6233,\n",
      "         -0.9623, -3.7855, -0.8715, -3.7745, -3.0162, -1.1780,  0.1758, -2.7365,\n",
      "          4.8934,  0.3046, -3.1761, -3.2762,  0.8937,  5.6606, -0.3623, -4.9554,\n",
      "         -3.2531, -0.0914,  1.6211, -0.9623]]), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "##pass the inputs\n",
    "with torch.no_grad():\n",
    "    outputs=model(**inputs)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c801435-3b98-4b66-8e16-978da8ff84a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch is running: {'name': '8484cf283848', 'cluster_name': 'docker-cluster', 'cluster_uuid': '4G6Yu1Q5R86hprBmt3km6w', 'version': {'number': '8.15.1', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '253e8544a65ad44581194068936f2a5d57c2c051', 'build_date': '2024-09-02T22:04:47.310170297Z', 'build_snapshot': False, 'lucene_version': '9.11.1', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "\n",
    "# Define the path to the Elasticsearch binary\n",
    "es_path = '/usr/share/elasticsearch/bin/elasticsearch'  # Update this to the correct path\n",
    "\n",
    "# Change ownership of Elasticsearch files without requiring a password\n",
    "#os.system('sudo chown -R daemon:daemon /usr/share/elasticsearch/bin/elasticsearch')  # Update this path as well\n",
    "\n",
    "# Start Elasticsearch server\n",
    "es_server = Popen(args=[es_path],\n",
    "                  stdout=PIPE, stderr=STDOUT)\n",
    "\n",
    "# Wait for Elasticsearch to start\n",
    "time.sleep(30)\n",
    "\n",
    "# Check if Elasticsearch is up and running\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:9200/\", auth=('elastic', '8Ffm8AV5DvjhzB3NsQVY'))  # Update the password\n",
    "    response.raise_for_status()  # Raise an error for bad responses\n",
    "    print(\"Elasticsearch is running:\", response.json())\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Error connecting to Elasticsearch:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d936334-9371-4d02-bd82-37010216dadf",
   "metadata": {},
   "source": [
    "# initialize Retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07abc5ff-b320-4055-920a-2f7dead1ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Document\n",
    "from haystack.nodes import BM25Retriever\n",
    "from haystack.document_stores import ElasticsearchDocumentStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bfd2810-1ad0-4d88-aa14-bd3eaa633e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This ElasticsearchDocumentStore has been built for Elasticsearch 7, but the detected version of the Elasticsearch server is 8.15.1. Unexpected behaviors or errors may occur due to version incompatibility.\n"
     ]
    }
   ],
   "source": [
    "document_store=ElasticsearchDocumentStore(\n",
    "    host=\"localhost\",\n",
    "    scheme=\"http\",\n",
    "    index=\"document\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "494b7644-b3af-4df9-85b3-38a921d3a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=BM25Retriever(document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af36679c-d3eb-427e-9e3e-1567ad3af1c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for split, df in dfs.items():\n",
    "    docs = [\n",
    "        Document(content= row[\"context\"],\n",
    "    meta={\"item_id\": row[\"title\"], \"question_id\": row[\"id\"],\n",
    "            \"split\": split}\n",
    "                )\n",
    "        for _,row in df.drop_duplicates(subset=\"context\").iterrows()]\n",
    "    document_store.write_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc081436-5a94-4eaf-870e-c860235d5ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents is 1875\n"
     ]
    }
   ],
   "source": [
    "document_count = document_store.client.count(index='default')[\"count\"]\n",
    "print(f\"Number of documents is {document_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddd92b2b-560b-4090-9386-00a753f080c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id = \"B0074BW614\"\n",
    "query = \"Is it good for reading?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee30765d-faeb-44cd-a15a-6924c53797a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_doc=retriever.retrieve(\n",
    "    query=query,top_k=3,filters={\"item_id\":[item_id],\"split\":[\"train\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de092e32-35f8-4bf3-854c-d9e97a8640a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "Item ID: B0074BW614\n",
      "Split: train\n",
      "Question ID: 868e311275e26dbafe5af70774a300f3\n",
      "Content: This is a gift to myself.  I have been a kindle user for 4 years and this is my third one.  I never thought I would want a fire for I mainly use it for book reading.  I decided to try the fire for when I travel I take my laptop, my phone and my iPod classic.  I love my iPod but watching movies on the plane with it can be challenging because it is so small. Laptops battery life is not as good as the Kindle.  So the Fire combines for me what I needed all three to do. So far so good.\n",
      "Score:0.6859896945894133 \n",
      "\n",
      "\n",
      "Document 2:\n",
      "Item ID: B0074BW614\n",
      "Split: train\n",
      "Question ID: 998d564607f10bf6dbbd20b33b8fbbf1\n",
      "Content: Plays Netflix great, WiFi capability has great range. Resolution on the screen is AMAZING! For the price you cannot go wrong. Bought one for my spouse and myself after becoming addicted to hers! Our son LOVES it and it is great for reading books when no light is available. Amazing sound but I suggest good headphones to really hear it all.Battery life is super long and can go 3 or 4 days without a recharge from moderate use.A steal at $199.99.\n",
      "Score:0.6848480045959734 \n",
      "\n",
      "\n",
      "Document 3:\n",
      "Item ID: B0074BW614\n",
      "Split: train\n",
      "Question ID: 3ecfc76edee933ba1f202069b4fe7847\n",
      "Content: I've used an e-reader since the Rocket ebook in 1999, and I've always believed I wanted only an ebook reader with no other features. I don't get out much, so my computer is convenient for everything else.I've had several Kindles and was happy with all of them, but I had recently played around with my brother's tablet. When my last Kindle died, I decided to replace it with the Kindle Fire. I chose the smaller one because I was concerned about my arthritic hands holding a larger device for long periods. The 7\" is just perfect for me. It's light enough that I can hold it to read, but the larger screen compared to the Kindle makes for easier reading. I love the color, something I never thought would make a difference to me.Oddly enough, high on my favorite list is the ability to review a book as soon as I reach the end. I have written reviews of every book I read on a readers social media site, but I have seldom put in the extra effort to come to Amazon to write a review. On the Kindle Fire, as soon as I come to the end of a book, a review page pops up so I can review it while it's fresh on my mind, and I'm reviewing everything I read.I didn't realize when I placed my order that I was ordering that the device had special offers. I've always thought I would not want to be subject to advertising when I was reading. However, I discovered that the special offers are discreet and no distraction at all. I've even found myself going to the special offers page a time or two to see what's on offer.The only negative is that the battery doesn't last very long. However, with the PowerFast charger, it doesn't take long to charge the battery.I think folks like me who have always used a dedicated ereader and never even used a touch screen will be pleasantly surprised with the Kindle Fire, and people who are used to smartphones and tablets will find everything they expect in a device.Update 11/8/13: I still think the Kindle Fire is a fantastic product, and I use it occasionally for games. However, I have gone back to my Kindle Keyboard for reading novels. The arthritis in my shoulders, elbows, and hands has  worsened since I've been using the Kindle Fire, and even using the device for a short while increases the pain significantly. I can tolerate it for short periods to play a few games. However, I simply can't hold the Kindle Fire long enough for reading. This won't be an issue for most people, but I wanted to mention it for those people who might have similar problems.\n",
      "Score:0.6580296604181661 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(ret_doc):\n",
    "    print(f\"Document {i + 1}:\")\n",
    "    print(f\"Item ID: {doc.meta['item_id']}\")\n",
    "    print(f\"Split: {doc.meta['split']}\")\n",
    "    print(f\"Question ID: {doc.meta['question_id']}\")\n",
    "    print(f\"Content: {doc.content}\")\n",
    "    print(f\"Score:{doc.score} \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57233780-30f2-427d-a61f-0111c536e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import FARMReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf6d952a-4415-4740-a9d0-5ffebbf449f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nebiyu/miniconda3/envs/tune/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at deepset/minilm-uncased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = \"deepset/minilm-uncased-squad2\"\n",
    "max_seq_length, doc_stride = 384, 128\n",
    "reader = FARMReader(model_name_or_path=model_ckpt, progress_bar=False,\n",
    " max_seq_len=max_seq_length, doc_stride=doc_stride,\n",
    " return_no_answer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d275f4db-6c78-4888-a80d-082905574d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'How much music can this hold?', 'no_ans_gap': 12.648091793060303, 'answers': [<Answer {'answer': '6000 hours', 'type': 'extractive', 'score': 0.5293058156967163, 'context': 'An MP3 is about 1 MB/minute, so about 6000 hours depending on file size.', 'offsets_in_document': [{'start': 38, 'end': 48}], 'offsets_in_context': [{'start': 38, 'end': 48}], 'document_ids': ['e344757014e804eff50faa3ecf1c9c75'], 'meta': {}}>]}\n"
     ]
    }
   ],
   "source": [
    "print(reader.predict_on_texts(question=question,texts=[context],top_k=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d915ea85-3dc4-402a-b4af-d351b0000f56",
   "metadata": {},
   "source": [
    "# lets make a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d889307-b613-46ea-80f1-8c568abd5250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.pipelines import ExtractiveQAPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4d826b6-e56e-470d-b2cf-2ac90024915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline=ExtractiveQAPipeline(reader,retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d3d7be7-94a1-462a-adf3-080a07807024",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ExtractiveQAPipeline.run() got an unexpected keyword argument 'top_k_retriever'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m n_answers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[0;32m----> 3\u001b[0m preds\u001b[38;5;241m=\u001b[39m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtop_k_retriever\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m               \u001b[49m\u001b[43mtop_k_reader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_answers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m               \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mitem_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m              \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: ExtractiveQAPipeline.run() got an unexpected keyword argument 'top_k_retriever'"
     ]
    }
   ],
   "source": [
    "n_answers=3\n",
    "\n",
    "preds=pipeline.run(query=query,\n",
    "                top_k_retriever=3,\n",
    "               top_k_reader=n_answers,\n",
    "               filters={\"item_id\":[item_id],\"split\":[\"train\"]}\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b97c44c8-1f47-4c34-a28d-ed54873ca7a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[38;5;241m.\u001b[39mrun(query\u001b[38;5;241m=\u001b[39mquery, top_k_retriever\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, top_k_reader\u001b[38;5;241m=\u001b[39mn_answers,\n\u001b[1;32m      2\u001b[0m  filters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: [item_id], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "preds = pipe.run(query=query, top_k_retriever=3, top_k_reader=n_answers,\n",
    " filters={\"item_id\": [item_id], \"split\":[\"train\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b8668-b194-4b3b-b7d6-e7dd86ad9b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
